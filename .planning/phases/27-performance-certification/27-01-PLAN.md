---
phase: 27-performance-certification
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/27-performance-certification/27-01-SUMMARY.md
autonomous: true

must_haves:
  truths:
    - "Lighthouse Performance score documented for desktop and mobile"
    - "LCP, CLS metrics captured and verified against targets"
    - "Production build performance validated (not dev server)"
  artifacts:
    - path: ".planning/phases/27-performance-certification/27-01-SUMMARY.md"
      provides: "Lighthouse test results documentation"
      contains: "Performance Score"
  key_links:
    - from: "npm run build"
      to: "Lighthouse audit"
      via: "production build required for accurate metrics"
      pattern: "npm run build"
---

<objective>
Run Lighthouse Performance audits on production build to validate performance gates PERF-01, PERF-02, PERF-03, PERF-04, and CERT-02.

Purpose: Establish baseline performance scores for v2.0 visual excellence to verify all visual upgrades maintain 95+ Lighthouse score.

Output: Documented Lighthouse scores for desktop and mobile with LCP, CLS metrics. If scores fail targets, document specific issues for remediation.
</objective>

<execution_context>
@C:\Users\דודאלמועלם\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\דודאלמועלם\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/27-performance-certification/27-CONTEXT.md
@.planning/phases/27-performance-certification/27-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build and start production server</name>
  <files>None (build artifacts only)</files>
  <action>
Build production bundle and start local production server for Lighthouse testing:

```bash
# Build production bundle
npm run build

# Start production server (keep running in background for testing)
# Note: Server runs on http://localhost:3000
npm start
```

Wait for server to be ready before proceeding. Production build is REQUIRED - dev server showed 34 score vs expected 95+ in Phase 26-05 testing.
  </action>
  <verify>Server responds at http://localhost:3000 with production bundle</verify>
  <done>Production server running locally, ready for Lighthouse audits</done>
</task>

<task type="auto">
  <name>Task 2: Run Lighthouse audits and document results</name>
  <files>.planning/phases/27-performance-certification/27-01-SUMMARY.md</files>
  <action>
Run Lighthouse audits using Chrome DevTools or CLI. Execute 3 runs each for desktop and mobile, use median scores.

**Desktop Testing:**
```bash
# Run 3 desktop audits
npx lighthouse http://localhost:3000 --only-categories=performance --preset=desktop --output=json --output-path=./lighthouse-desktop-1.json
npx lighthouse http://localhost:3000 --only-categories=performance --preset=desktop --output=json --output-path=./lighthouse-desktop-2.json
npx lighthouse http://localhost:3000 --only-categories=performance --preset=desktop --output=json --output-path=./lighthouse-desktop-3.json
```

**Mobile Testing:**
```bash
# Run 3 mobile audits (default is mobile emulation)
npx lighthouse http://localhost:3000 --only-categories=performance --output=json --output-path=./lighthouse-mobile-1.json
npx lighthouse http://localhost:3000 --only-categories=performance --output=json --output-path=./lighthouse-mobile-2.json
npx lighthouse http://localhost:3000 --only-categories=performance --output=json --output-path=./lighthouse-mobile-3.json
```

**Extract and document these metrics:**
- Performance Score (target: 95+, minimum: 90+)
- LCP - Largest Contentful Paint (target: <1.5s desktop, <2.5s mobile)
- CLS - Cumulative Layout Shift (target: 0)
- FCP - First Contentful Paint
- TBT - Total Blocking Time
- SI - Speed Index

**Document results in summary with:**
- All 6 runs (3 desktop, 3 mobile)
- Median scores highlighted
- Pass/fail status for each metric vs targets
- Any specific diagnostics if failing

**Targets from REQUIREMENTS.md:**
- PERF-01: Desktop 95+ (90+ acceptable minimum)
- PERF-02: Mobile 95+ (90+ acceptable minimum)
- PERF-03: LCP <1.5s desktop, <2.5s mobile
- PERF-04: CLS = 0
- CERT-02: 95+ maintained after all visual upgrades

Clean up JSON files after extracting metrics.
  </action>
  <verify>Summary includes median scores for both desktop and mobile with all Core Web Vitals</verify>
  <done>Lighthouse scores documented: Desktop [score]/100, Mobile [score]/100, CLS [value], LCP [time]s - PASS/FAIL status clear</done>
</task>

</tasks>

<verification>
- [ ] Production build used (not dev server)
- [ ] 3+ runs executed for each profile (variance captured)
- [ ] Median scores calculated and documented
- [ ] LCP, CLS metrics captured for both profiles
- [ ] Pass/fail status clear against 95+ target (90+ minimum)
</verification>

<success_criteria>
Lighthouse audit results documented with:
1. Desktop Performance score (median of 3 runs)
2. Mobile Performance score (median of 3 runs)
3. LCP values for both profiles
4. CLS values for both profiles (must be 0)
5. Clear PASS/FAIL determination against PERF-01, PERF-02, PERF-03, PERF-04, CERT-02
</success_criteria>

<output>
After completion, create `.planning/phases/27-performance-certification/27-01-SUMMARY.md`
</output>
